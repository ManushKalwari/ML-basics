{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "04b77dad-a962-4f00-bb36-f241bb677475",
      "metadata": {
        "id": "04b77dad-a962-4f00-bb36-f241bb677475"
      },
      "source": [
        "# Train/Test Split & Shuffling\n",
        "\n",
        "In machine learning, we need to evaluate whether a model can **generalize** to unseen data.  \n",
        "To do this, we prepare the dataset by:\n",
        "\n",
        "1. **Splitting the data**  \n",
        "   - **Training set** → used to learn model parameters.  \n",
        "   - **Testing set** → kept unseen until final evaluation.  \n",
        "   - Common ratios: **80/20** or **70/30** (sometimes 60/20/20 with a validation set).\n",
        "\n",
        "2. **Shuffling the data**  \n",
        "   - Prevents bias when data is ordered (e.g., sorted labels, time sequence).  \n",
        "   - Ensures both train and test sets represent the overall dataset fairly.\n",
        "\n",
        "3. **Outcome**  \n",
        "   - Training set → guides learning.  \n",
        "   - Test set → provides an unbiased estimate of model performance.  \n",
        "\n",
        "> This step ensures that our model evaluation reflects **true generalization ability**, not just memorization of the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaed5e2a-bb00-463d-81a1-305700a7d085",
      "metadata": {
        "id": "aaed5e2a-bb00-463d-81a1-305700a7d085"
      },
      "source": [
        "### Train/Test Split with NumPy\n",
        "Here we use NumPy to shuffle indices and split the dataset into 80% training and 20% testing sets.  \n",
        "This ensures that both sets are randomly sampled and representative of the whole dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf6c060-3963-40bf-b91a-a28eca1941b7",
      "metadata": {
        "id": "aaf6c060-3963-40bf-b91a-a28eca1941b7",
        "outputId": "875841a1-4043-4e65-e0d6-0807ee11ea70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (40, 2)  Test shape: (10, 2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dummy dataset\n",
        "X = np.arange(100).reshape(50, 2)   # 50 samples, 2 features\n",
        "y = np.arange(50)                   # labels\n",
        "\n",
        "# Shuffle indices\n",
        "indices = np.arange(len(X))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Train/test split (80/20)\n",
        "split = int(0.8 * len(X))\n",
        "train_idx, test_idx = indices[:split], indices[split:]\n",
        "\n",
        "X_train, X_test = X[train_idx], X[test_idx]\n",
        "y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c2769b-58ea-482b-9e5d-760b63dd8f02",
      "metadata": {
        "id": "d9c2769b-58ea-482b-9e5d-760b63dd8f02"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7bdf3647-7292-4b1d-8298-a78a478f6769",
      "metadata": {
        "id": "7bdf3647-7292-4b1d-8298-a78a478f6769"
      },
      "source": [
        "### Train/Test Split with Scikit-learn\n",
        "Scikit-learn provides a convenient `train_test_split` function that handles both shuffling and splitting in one step.  \n",
        "We use `test_size=0.2` for an 80/20 split and fix a `random_state` for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8c7120-0740-4cae-973c-89ee8a79374e",
      "metadata": {
        "id": "dd8c7120-0740-4cae-973c-89ee8a79374e",
        "outputId": "ac5c6caf-f788-4a11-8a76-a3f6fcfc87e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (40, 2)  Test shape: (10, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.arange(100).reshape(50, 2)\n",
        "y = np.arange(50)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf25a3f9-abe3-48a3-b0b4-96ca70590331",
      "metadata": {
        "id": "bf25a3f9-abe3-48a3-b0b4-96ca70590331"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "36416940-3822-4949-8d55-d5c49fb95692",
      "metadata": {
        "id": "36416940-3822-4949-8d55-d5c49fb95692"
      },
      "source": [
        "### Train/Test Split with PyTorch\n",
        "In PyTorch, we wrap the data into a `TensorDataset` and then use `random_split` to divide it into training and test sets.  \n",
        "Finally, we create `DataLoader`s to iterate through mini-batches during training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15074c2d-1f1f-4708-a5d8-f291c81864ae",
      "metadata": {
        "id": "15074c2d-1f1f-4708-a5d8-f291c81864ae",
        "outputId": "58255313-8e5f-4879-b530-50d2337690d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batches: 5  Test batches: 2\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "X = torch.arange(100).reshape(50, 2).float()\n",
        "y = torch.arange(50)\n",
        "\n",
        "# Combine X and y into a dataset\n",
        "dataset = TensorDataset(X, y)\n",
        "\n",
        "# Train/test split sizes\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders (shuffle training set)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "print(\"Train batches:\", len(train_loader), \" Test batches:\", len(test_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52dd21b-1851-46de-ab30-27b8e202bc22",
      "metadata": {
        "id": "f52dd21b-1851-46de-ab30-27b8e202bc22"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (pytorch-dev)",
      "language": "python",
      "name": "pytorch-dev"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}